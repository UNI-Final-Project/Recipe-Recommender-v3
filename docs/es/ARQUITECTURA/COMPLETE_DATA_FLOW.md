# ğŸ—ºï¸ MAPA COMPLETO DEL SISTEMA

## 1ï¸âƒ£ ENTRADA DEL USUARIO

```
Usuario escribe:
"Quiero una receta con pasta y tomate"
         â†“
Sistema recibe POST request a /recommend
         â†“
Estructura JSON:
{
  "query": "Quiero una receta con pasta y tomate"
}
```

---

## 2ï¸âƒ£ PROCESAMIENTO EN FASTAPI

```
FastAPI app.py recibe request
         â†“
Valida con Pydantic model
         â†“
Extrae la consulta: "pasta y tomate"
         â†“
Inicia logging (app_logger)
         â†“
Llama funciÃ³n recommend_for_new_user()
```

---

## 3ï¸âƒ£ GENERACIÃ“N DE EMBEDDINGS

```
OpenAI API
         â†“
text-embedding-3-small
         â†“
Transforma: "pasta y tomate"
  â†“
Vector: [0.123, -0.456, 0.789, ...]
  â†“
1536 dimensiones
```

---

## 4ï¸âƒ£ BÃšSQUEDA EN QDRANT

```
Qdrant Vector Database
         â†“
Query embedding: [0.123, -0.456, ...]
         â†“
Calcula similitud con 53,064 vectores
         â†“
Top 6 resultados mÃ¡s cercanos:
  1. Classic Spaghetti (0.95)
  2. Pasta al Pomodoro (0.92)
  3. Tomato Fettuccine (0.88)
  4. Creamy Tomato Pasta (0.85)
  5. Garlic Pasta (0.82)
  6. Pasta Marinara (0.80)
```

---

## 5ï¸âƒ£ RANKING HÃBRIDO

```
Para cada receta:
         â†“
Calcula dos scores:
  â€¢ Semantic Score: 0.95 (de Qdrant)
  â€¢ Popularity Score: 4.8â˜… / 5 = 0.96
         â†“
Hybrid Score = (0.7 Ã— 0.95) + (0.3 Ã— 0.96)
            = 0.665 + 0.288
            = 0.953
         â†“
Ranking Final:
  1. Classic Spaghetti (0.953)
  2. Pasta al Pomodoro (0.941)
  3. Creamy Tomato (0.925)
```

---

## 6ï¸âƒ£ EXTRACCIÃ“N DE DATOS

```
Base de datos food.pkl (53,064 recetas)
         â†“
Por cada receta en top 3:
  â€¢ nombre: "Classic Spaghetti al Pomodoro"
  â€¢ descripciÃ³n: "Traditional Italian pasta..."
  â€¢ ingredientes: ["spaghetti", "tomates", ...]
  â€¢ instrucciones: ["Cocinar pasta", "Preparar salsa", ...]
  â€¢ calificaciÃ³n_promedio: 4.8
```

---

## 7ï¸âƒ£ RECOLECCIÃ“N DE MÃ‰TRICAS

```
Monitoreo (monitoring_logger)
         â†“
Mide latencia: 245ms
Registra request: POST /recommend
Cuenta error: No
Recuenta total: total_requests += 1
         â†“
Anomaly Detector verifica:
  Â¿Latencia > 500ms? No âœ“
  Â¿Error rate > 5%? No âœ“
  Â¿Spike en trÃ¡fico? No âœ“
```

---

## 8ï¸âƒ£ TRACKING EN MLFLOW

```
MLflow Tracking URI: ./mlruns
         â†“
Inicia run en experimento:
  "recipe-recommendations"
         â†“
Registra parÃ¡metros:
  - embedding_model: text-embedding-3-small
  - alpha: 0.7
  - n_results: 3
         â†“
Registra mÃ©tricas:
  - latency_ms: 245
  - semantic_score: 0.95
         â†“
Fin de run â†’ Guardado
```

---

## 9ï¸âƒ£ TRADUCCIÃ“N AL ESPAÃ‘OL

```
Respuesta en inglÃ©s (Qdrant):
{
  "name": "Classic Spaghetti al Pomodoro",
  "description": "Traditional Italian pasta..."
}
         â†“
GPT-4 Translation Chain
         â†“
Respuesta en espaÃ±ol:
{
  "nombre": "ClÃ¡sico Espaguetis al Pomodoro",
  "descripciÃ³n": "Pasta italiana tradicional..."
}
```

---

## ğŸ”Ÿ RESPUESTA AL USUARIO

```
JSON Response (HTTP 200):
{
  "recetas": [
    {
      "nombre": "ClÃ¡sico Espaguetis al Pomodoro",
      "descripciÃ³n": "Pasta italiana tradicional...",
      "ingredientes": ["espaguetis", "tomates", ...],
      "instrucciones": ["Cocinar pasta", ...],
      "calificaciÃ³n_promedio": 4.8
    },
    ...mÃ¡s recetas...
  ]
}
         â†“
Retorna al cliente en <500ms
```

---

## ğŸ”„ LOGGING Y AUDITORÃA

```
app_logger registra:
  "2025-12-31 00:19:18 - Recommendation request received"
         â†“
monitoring_logger registra:
  "Latency: 245ms, Error: False, Status: 200"
         â†“
mlops_logger registra:
  "Model: hybrid_ranker v1.0.0, Confidence: 0.95"
         â†“
Archivo logs/app_YYYYMMDD.json
{
  "timestamp": "2025-12-31T00:19:18",
  "endpoint": "/recommend",
  "latency_ms": 245,
  "model": "hybrid_ranker",
  "status": "success"
}
```

---

## ğŸ“Š VISUALIZACIÃ“N COMPLETA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         USUARIO â†’ QUERY: "pasta y tomate"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ FastAPI /recommend
            â”‚ (app.py line 268)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ OpenAI â”‚  â”‚ Qdrant â”‚  â”‚ Loggingâ”‚
    â”‚Embed   â”‚  â”‚Search  â”‚  â”‚(json)  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚           â”‚          â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  Ranking HÃ­brido        â”‚ â”‚
    â”‚  Î±=0.7 semantic +       â”‚ â”‚
    â”‚  (1-Î±) popularity       â”‚ â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
         â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  GPT-4 Translation    â”‚  â”‚
    â”‚  English â†’ Spanish    â”‚  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
    â”‚  MLflow Tracking             â”‚
    â”‚  ./mlruns/experiment_id/run  â”‚
    â”‚  - params                    â”‚
    â”‚  - metrics                   â”‚
    â”‚  - artifacts                 â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  JSON Response (HTTP 200) â”‚
    â”‚  3 recetas con details    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  USUARIO
```

---

## ğŸ¯ FLUJO DE DATOS ALTERNO: /health

```
GET /health
    â†“
health_check()
    â†“
Retorna:
  {
    "status": "healthy",
    "num_recipes": 53064,
    "model_production": "hybrid_ranker v1.0.0"
  }
    â†“
HTTP 200 OK
```

---

## ğŸ“ˆ FLUJO DE DATOS ALTERNO: /metrics

```
GET /metrics
    â†“
get_metrics(window_minutes=60)
    â†“
Recolecta:
  â€¢ total_requests: 42
  â€¢ avg_latency_ms: 245.5
  â€¢ error_rate: 0.0%
  â€¢ p50, p95, p99 latencies
    â†“
HTTP 200 OK con JSON
```

---

## ğŸ›ï¸ FLUJO DE DATOS ALTERNO: /models

```
GET /models
    â†“
model_registry.list_models()
    â†“
Retorna:
  [
    {
      "model_id": "hybrid_ranker",
      "version": "1.0.0",
      "status": "production"
    }
  ]
    â†“
HTTP 200 OK
```

---

## ğŸ”„ FLUJO DE DATOS ALTERNO: /retrain/check

```
POST /retrain/check
    â†“
auto_scheduler.check_and_schedule_retraining()
    â†“
Verifica:
  â€¢ Data drift detectado? No
  â€¢ Performance degradaciÃ³n? No
  â€¢ DÃ­as desde Ãºltimo training? 0
    â†“
Retorna:
  {
    "needs_retraining": false,
    "recommendation": "No retraining needed"
  }
    â†“
HTTP 200 OK
```

---

## ğŸ” FLOW DE SEGURIDAD

```
Request entra
    â†“
CORS check âœ“
    â†“
Request validation (Pydantic) âœ“
    â†“
API key check (si aplica) âœ“
    â†“
Rate limiting (implementable) âœ“
    â†“
Procesa request
    â†“
Logging para auditorÃ­a âœ“
    â†“
Response con HTTP status correcto âœ“
```

---

## âœ… MONITOREO CONTINUO

```
Mientras servidor estÃ¡ corriendo:

Cada request:
  â€¢ metrics_collector.record() â†’ latencia
  â€¢ app_logger.info() â†’ log
  â€¢ MLflow tracking â†’ experimento

Cada minuto:
  â€¢ anomaly_detector.detect() â†’ chequea anomalÃ­as
  â€¢ health_monitor.check() â†’ verifica salud

Cada hora:
  â€¢ Logs rotados automÃ¡ticamente
  â€¢ MÃ©tricas agregadas
  â€¢ Reports generados
```

---

## ğŸ“Š ESTADO FINAL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… FLUJO COMPLETO OPERATIVO           â”‚
â”‚                                        â”‚
â”‚  â€¢ RecepciÃ³n de request: 50ms          â”‚
â”‚  â€¢ Procesamiento: 150ms                â”‚
â”‚  â€¢ Ranking: 30ms                       â”‚
â”‚  â€¢ TraducciÃ³n: 50ms                    â”‚
â”‚  â€¢ Response: <10ms                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  Total: ~300ms                         â”‚
â”‚                                        â”‚
â”‚  âœ… Latencia aceptable (<500ms)        â”‚
â”‚  âœ… Tasa de error: 0%                  â”‚
â”‚  âœ… Logging activo                     â”‚
â”‚  âœ… Monitoreo en tiempo real            â”‚
â”‚  âœ… MLflow tracking funcionando        â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CONCLUSIÃ“N

El flujo completo del sistema desde usuario hasta respuesta estÃ¡ 100% documentado y operativo:

1. âœ… Usuario envÃ­a query
2. âœ… FastAPI procesa
3. âœ… OpenAI genera embeddings
4. âœ… Qdrant busca
5. âœ… Ranking hÃ­brido ordena
6. âœ… MÃ©tricas se recolectan
7. âœ… MLflow registra
8. âœ… GPT-4 traduce
9. âœ… Response se envÃ­a
10. âœ… Logs se guardan

**Â¡SISTEMA COMPLETO Y FUNCIONANDO!** ğŸ‰
